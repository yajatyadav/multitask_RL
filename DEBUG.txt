[robosuite WARNING] No private macro file found! (__init__.py:7)
[robosuite WARNING] It is recommended to use a private macro file (__init__.py:8)
[robosuite WARNING] To setup, run: python /home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (__init__.py:9)
/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:681: DeprecationWarning: jax.interpreters.xla.pytype_aval_mappings is deprecated.
  jax.interpreters.xla.pytype_aval_mappings[onp.ndarray])
<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yajatyadav (rail-iterated-offline-rl) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/wandb/analytics/sentry.py:259: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.
  self.scope.user = {"email": email}  # noqa
/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/wandb/analytics/sentry.py:259: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.
  self.scope.user = {"email": email}  # noqa
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /tmp/tmpulk6m341/wandb/run-20251029_190014-is0e5ko5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run test_combined_encoder_pipeline_sd00020251029_190013
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yajatyadav/multitask_RL
wandb: üöÄ View run at https://wandb.ai/yajatyadav/multitask_RL/runs/is0e5ko5
wandb: WARNING Symlinked 7 files into the W&B run directory, call wandb.save again to sync new files.
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TODO(YY): Normalization path not implemented for libero_90-kitchen_scene2-open_the_top_drawer_of_the_cabinet
evaluation environment will return keys:  {'states'}
/home/yajatyadav/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
TODO(YY): Normalization path not implemented for libero_90-kitchen_scene2-open_the_top_drawer_of_the_cabinet
evaluation environment will return keys:  {'states'}
processing dataset for task open_the_top_drawer_of_the_cabinet
the size of the dataset for task open_the_top_drawer_of_the_cabinet is 3765, and is_positive_task=True
the total size of the dataset is 3765
Made env and datasets.Train dataset size: 3765
Traceback (most recent call last):
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/main.py", line 378, in <module>
    app.run(main)
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/absl/app.py", line 316, in run
    _run_main(main, args)
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/absl/app.py", line 261, in _run_main
    sys.exit(main(argv))
             ^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/main.py", line 175, in main
    agent = agent_class.create(
            ^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/agents/acfql.py", line 317, in create
    network_params = network_def.init(init_rng, **network_args)['params']
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/utils/flax_utils.py", line 45, in __call__
    out[key] = self.modules[key](*value)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/utils/networks.py", line 256, in __call__
    inputs = jnp.concatenate([observations, actions, times], axis=-1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py", line 4631, in concatenate
    arrays = util.ensure_arraylike_tuple("concatenate", arrays)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/jax/_src/numpy/util.py", line 167, in ensure_arraylike_tuple
    check_arraylike(fun_name, *tup)
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/.venv/lib/python3.11/site-packages/jax/_src/numpy/util.py", line 182, in check_arraylike
    raise TypeError(msg.format(fun_name, type(arg), pos))
TypeError: concatenate requires ndarray or scalar arguments, got <class 'dict'> at position 0.
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mtest_combined_encoder_pipeline_sd00020251029_190013[0m at: [34mhttps://wandb.ai/yajatyadav/multitask_RL/runs/is0e5ko5[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../../tmp/tmpulk6m341/wandb/run-20251029_190014-is0e5ko5/logs[0m
