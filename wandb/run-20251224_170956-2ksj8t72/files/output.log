TODO(YY): Normalization path not implemented for libero_90-kitchen_scene2-open_the_top_drawer_of_the_cabinet
evaluation environment will return keys:  {'agentview_image', 'proprio', 'robot0_eye_in_hand_image', 'language'}
suites: ['libero_90'], scenes: ['kitchen_scene2']
All possible envs, sorted alphabetically: there are 1 total envs
 len(envs_to_eval)=6 Environments to evaluate: ['libero_spatial-pick_up_the_black_bowl_between_the_plate_and_the_ramekin_and_place_it_on_the_plate', 'libero_object-pick_up_the_alphabet_soup_and_place_it_in_the_basket', 'libero_goal-open_the_middle_drawer_of_the_cabinet', 'libero_90-KITCHEN_SCENE10_close_the_top_drawer_of_the_cabinet', 'libero_90-LIVING_ROOM_SCENE1_pick_up_the_alphabet_soup_and_put_it_in_the_basket', 'libero_90-STUDY_SCENE1_pick_up_the_book_and_place_it_in_the_front_compartment_of_the_caddy']
/home/yajatyadav/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TODO(YY): Normalization path not implemented for libero_90-kitchen_scene2-open_the_top_drawer_of_the_cabinet
evaluation environment will return keys:  {'agentview_image', 'proprio', 'robot0_eye_in_hand_image', 'language'}
suites: ['libero_90'], scenes: ['kitchen_scene2']
All possible envs, sorted alphabetically: there are 1 total envs
 len(envs_to_eval)=6 Environments to evaluate: ['libero_spatial-pick_up_the_black_bowl_between_the_plate_and_the_ramekin_and_place_it_on_the_plate', 'libero_object-pick_up_the_alphabet_soup_and_place_it_in_the_basket', 'libero_goal-open_the_middle_drawer_of_the_cabinet', 'libero_90-KITCHEN_SCENE10_close_the_top_drawer_of_the_cabinet', 'libero_90-LIVING_ROOM_SCENE1_pick_up_the_alphabet_soup_and_put_it_in_the_basket', 'libero_90-STUDY_SCENE1_pick_up_the_book_and_place_it_in_the_front_compartment_of_the_caddy']
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
suites: ['libero_90'], scenes: ['kitchen_scene2']
ðŸ¤ªðŸ¤ªðŸ¤ª all_libero_env_names: {'libero_90': ['libero_90-KITCHEN_SCENE2_open_the_top_drawer_of_the_cabinet', 'libero_90-KITCHEN_SCENE2_put_the_black_bowl_at_the_back_on_the_plate', 'libero_90-KITCHEN_SCENE2_put_the_black_bowl_at_the_front_on_the_plate', 'libero_90-KITCHEN_SCENE2_put_the_middle_black_bowl_on_the_plate', 'libero_90-KITCHEN_SCENE2_put_the_middle_black_bowl_on_top_of_the_cabinet', 'libero_90-KITCHEN_SCENE2_stack_the_black_bowl_at_the_front_on_the_black_bowl_in_the_middle', 'libero_90-KITCHEN_SCENE2_stack_the_middle_black_bowl_on_the_back_black_bowl']}
ðŸ¤ªðŸ¤ªðŸ¤ª distinct_scenes: {'libero_90': ['KITCHEN_SCENE2']}
ðŸ˜ˆðŸ˜ˆðŸ˜ˆ suite='LIBERO_90' scene='KITCHEN_SCENE2' , there are 7 files for this suite + scene
ðŸ˜ˆðŸ˜ˆðŸ˜ˆ target_task_name='open_the_top_drawer_of_the_cabinet'
ðŸ¥³ðŸ¥³ðŸ¥³ j=0 Dataset open_the_top_drawer_of_the_cabinet has 3765, and flip_rewards=False, relabeled to target_task_name='open_the_top_drawer_of_the_cabinet'
the total size of the dataset is 3765
Evaluating agent with num_samples: 1
[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Traceback (most recent call last):                                                                                                                                                                                                                                                                                                
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/evaluation/eval_libero_best_of_N.py", line 158, in <module>                                                                                                                                                                                                
    sweep_best_of_N(n_vals)
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/evaluation/eval_libero_best_of_N.py", line 75, in sweep_best_of_N
    eval_info = eval_agent(agent, example_batch, names_to_return, logger)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/evaluation/eval_libero_best_of_N.py", line 127, in eval_agent
    eval_info, trajs, renders = evaluate(
                                ^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/evaluation_libero.py", line 118, in evaluate
    action = actor_fn(observations=observation_for_actor)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/evaluation_libero.py", line 20, in wrapped
    return f(*args, rng=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yajatyadav/multitask_reinforcement_learning/multitask_RL/agents/acifql.py", line 155, in sample_actions
    full_action_dim = self.config["action_dim"] * (self.config["horizon_length"] if self.config["action_chunking"] else 1)
                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
